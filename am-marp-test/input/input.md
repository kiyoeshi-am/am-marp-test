---
marp: true
theme: default
paginate: true
header: "Claude Codeを使って不確実性と戦う"
footer: "@erukiti"
---

<!-- _header: 'Claude Codeを使って不確実性と戦う' -->

## Clade Codeを使って不確実性と戦う

### (2025/07/17) Claude Code Meetup #claudecode_findy

---

## 自己紹介

<div style="position: absolute; top: 100px; right: 100px;">
<div style="display: flex; gap: 1em;">
<img src="./profile.png" width="100px" height="100px" />
<img src="./profile-new.png" width="100px" height="100px" />
</div>
</div>

<div style="font-size:0.9em">

- erukiti (左が旧アイコン)
- 株式会社AlgomaticのAIエンジニア
    - 生成AIで人類を幸せにする会社です！アポドリとかリクルタとかDMM動画ゲーム翻訳とかにじボイスとかやってます！
    - スライド作り下手くそすぎて宣伝スライド仕込めてないんですが、興味ある人は「Algomatic（アルゴマティック）」で検索して！！！
- 2023年から本当の意味で「LLMにAll in one」です
    - 興味ある人は「Algomatic erukiti 入社エントリ」読んでみて
    - 生成AI(LLM)がもたらす未来にしか興味ないです
- LLMプロダクト専業で、チャット型とかRAGやAIエージェントを作り続けています

</div>

---

## 散々語られているけど、極めて重要なこと

<div style="font-size: 0.8em">

- AIコーディングエージェント（というかLLM）の認知特性および知性は**人間と大きく違う**
    - 人間との会話なら期待値調整もできるが、人間とは明らかに違うので**無意味**
    - 一ヶ月前とモデルが変わることがザラ（先月ならこの言い方で通じたのに！）
    - 人間との会話作法では疲弊する
- AIはよかれと思って、とんでもないことをやらかす
    - 「この目的を達成するためには `rm -rf ~` が必要なんです！！！」
    - 「テストを通すために .ts を .js にリネームします！！！！」
- AIはギザギザのAGI（汎用人工知性）だと思っている
    - 部分的にはめちゃくちゃ賢い。人間よりも遙かに。
    - でも「この会話ができるなら、この言い方で通じるやろ」が全く通じない

## **ミドル以上の優秀なエンジニアとの対話を期待すると期待外れに終わる**

</div>

---

## 必然的にAIの使い方の **大前提**

<div style="font-size: 0.8em">

- AIに頼むタスクは小さくしなければいけない
    - でかいタスクは「とんでもないことをしがち」「制御に苦労する」「コンテキスト汚染」
    - **特にClaude4は200k contextしかない上に、Geminiよりも遙かにContext汚染に弱いので、contextが大きくなったら負けのゲーム**
- AIに頼むタスクは失敗を前提にしなければいけない
    - 同じタスクを三つくらいは投げるのが望ましい
    - temperatureが高いので、バリエーションは豊富
- AIの書くコードは提案であって、決して確定ではない
    - **油断した頃に「とんでもないもの」を差し込んでくる**

### **※ただし2・3世代先には事情が変わってるはず**

</div>


---

## 改めて今日のテーマ

## **Claude Codeを使って不確実性と戦う**

---

- 逆説的に考える
    - 確実性が高いものは、おそらく短期間でAIに置き換えられる
    - -> **つまり、確実性の高いことは、我々人類が取り組むべき課題ではない**
- でもそもそも、現代の開発において、100%の完璧なメンタルモデル無理くない？
    - 新しくjoinした
    - 急に人が失踪した
    - 生き証人がいない
    - メテオフォール
    - 事業開発！

---

## たとえば事業開発

- 2023年末からRAGやAIエージェント作ってた
- ところが、その頃、RAGやAIエージェントに関しての情報はArxivにあれば上等な方で、大抵の場合どこにも資料がない
    - RAGに関して制御可能な変数なんて、一番最初に雑に考えても、10個以上あるよね？
    - 評価どうやんの？
    - マネージドサービスもあるよね？精度は？
    - 精度上がっても、汎化できる？
    - 精度上げたとして、それは金になるの？

### **考えて実験して計測してを繰り返すしかない。**

---

## 正常ケースとして、Claude Codeでコーディングをさせる

Claude Code でコーディングをしてみた！の類いは、本当に有用な情報なのか？
コーディングというのは、あくまで開発プロセスのごく一部なのではないか？

もちろん、実際には話がここで分岐するはずで、「コーディングが多くを占めるからコーディングでいいんだ」も確実にあるはず

でも、そうじゃなくてコーディング以外を考えなければならないケースを取り上げたい

---

## 観測をする1: 脳内モデリングを強化させる（現状を把握する）

プロダクトにおいて脳内モデリングが100%になるのは難しい。

- コード分析をさせる
- コードから読み取れるべき情報を言語化させて、ズレを計測する
- あるI/Fに対するコードを書かせて、クセを計測する
- Mermaidなどの図を書かせる

---

## 観測をする2: 理想に至るためのギャップを観測する

- 理想像を書いた上で「現状は、先ほど記述した理想像とはほど遠い。どのあたりが現実かを精緻に調べて調査してレポートしてほしい」
- 「レポート結果を元に、ギャップが何かを詳細にまとめてほしい」
- 「ギャップをうめるために何が必要かを詳細にまとめてほしい」

## ある種のCoTで、TO-BE + AS-IS から gap（解決すべきこと）を導き出せる

---

## 観測をする3: わざと大きな実装をさせる

- 当然失敗する。むしろ、**どういう失敗をするかを観測する**
- バグだらけでも動けば、PoCとして使えるかもしれない
- ここでも重要なのは「ズレ」「クセ」を見ること

## **人間は脳内でどれだけ考えても、テキストに書き起こしてもだめで、実際に動くものを見てはじめて気づくことが多い**

---

## 観測をする4: 技術調査

- 現行のLLMは例外なく、ライブラリの使い方が下手くそ
- Claude Codeの場合はWebSearchとWebRequestをツールとして持ってるので、検索させるのが重要
- 知識ではなく「実測」のみを正しいものとして扱う